{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Assignment 2\n",
    "### Data Mining 7331 Section 403\n",
    "---\n",
    "- Brian Coari\n",
    "- Stephen Merritt\n",
    "- Cory Thigpen\n",
    "- Quentin Thomas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset tracks all Olympians' medal results from 1896-2016, as well as various physical attributes such as `Sex`, `Age`, `Weight`, and `Height`. In this lab we will (1) predict podium finishers using binary classification and (2) predict the sport a podium-finishing athlete played using multinomial classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "#### Section 1\n",
    "\n",
    "- (10pts) Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Country</th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Team</th>\n",
       "      <th>Games</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>City</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Event</th>\n",
       "      <th>Medal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>872</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>502.0</td>\n",
       "      <td>Ahmad Shah Abouwi</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>176</td>\n",
       "      <td>73</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1956 Summer</td>\n",
       "      <td>1956</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Hockey</td>\n",
       "      <td>Hockey</td>\n",
       "      <td>No Medal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>Jammal-ud-Din Affendi</td>\n",
       "      <td>M</td>\n",
       "      <td>28</td>\n",
       "      <td>176</td>\n",
       "      <td>73</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1936 Summer</td>\n",
       "      <td>1936</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Hockey</td>\n",
       "      <td>Hockey</td>\n",
       "      <td>No Medal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>Mohammad Anwar Afzal</td>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "      <td>177</td>\n",
       "      <td>73</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1948 Summer</td>\n",
       "      <td>1948</td>\n",
       "      <td>Summer</td>\n",
       "      <td>London</td>\n",
       "      <td>Football</td>\n",
       "      <td>Football</td>\n",
       "      <td>No Medal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3129</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>Mohammad Aktar</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>156</td>\n",
       "      <td>48</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1980 Summer</td>\n",
       "      <td>1980</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Moskva</td>\n",
       "      <td>Wrestling</td>\n",
       "      <td>Light-Flyweight, Freestyle</td>\n",
       "      <td>No Medal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8410</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>4628.0</td>\n",
       "      <td>Mohammad Daoud Anwary</td>\n",
       "      <td>M</td>\n",
       "      <td>22</td>\n",
       "      <td>172</td>\n",
       "      <td>76</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1964 Summer</td>\n",
       "      <td>1964</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Wrestling</td>\n",
       "      <td>Bantamweight, Freestyle</td>\n",
       "      <td>No Medal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  NOC      Country      ID                   Name Sex  Age  \\\n",
       "0         872  AFG  Afghanistan   502.0      Ahmad Shah Abouwi   M   25   \n",
       "1        1950  AFG  Afghanistan  1076.0  Jammal-ud-Din Affendi   M   28   \n",
       "2        1992  AFG  Afghanistan  1101.0   Mohammad Anwar Afzal   M   23   \n",
       "3        3129  AFG  Afghanistan  1745.0         Mohammad Aktar   M   17   \n",
       "4        8410  AFG  Afghanistan  4628.0  Mohammad Daoud Anwary   M   22   \n",
       "\n",
       "   Height  Weight         Team        Games  Year  Season       City  \\\n",
       "0     176      73  Afghanistan  1956 Summer  1956  Summer  Melbourne   \n",
       "1     176      73  Afghanistan  1936 Summer  1936  Summer     Berlin   \n",
       "2     177      73  Afghanistan  1948 Summer  1948  Summer     London   \n",
       "3     156      48  Afghanistan  1980 Summer  1980  Summer     Moskva   \n",
       "4     172      76  Afghanistan  1964 Summer  1964  Summer      Tokyo   \n",
       "\n",
       "       Sport                        Event     Medal  \n",
       "0     Hockey                       Hockey  No Medal  \n",
       "1     Hockey                       Hockey  No Medal  \n",
       "2   Football                     Football  No Medal  \n",
       "3  Wrestling   Light-Flyweight, Freestyle  No Medal  \n",
       "4  Wrestling      Bantamweight, Freestyle  No Medal  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('~/olympics/data/athletes_cleaned_merged.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 266954 entries, 0 to 266953\n",
      "Data columns (total 17 columns):\n",
      "Unnamed: 0    266954 non-null int64\n",
      "NOC           266954 non-null object\n",
      "Country       266954 non-null object\n",
      "ID            266954 non-null float64\n",
      "Name          266954 non-null object\n",
      "Sex           266954 non-null object\n",
      "Age           266954 non-null int64\n",
      "Height        266954 non-null int64\n",
      "Weight        266954 non-null int64\n",
      "Team          266954 non-null object\n",
      "Games         266954 non-null object\n",
      "Year          266954 non-null int64\n",
      "Season        266954 non-null object\n",
      "City          266954 non-null object\n",
      "Sport         266954 non-null object\n",
      "Event         266954 non-null object\n",
      "Medal         266954 non-null object\n",
      "dtypes: float64(1), int64(5), object(11)\n",
      "memory usage: 34.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intial data set contained the following data of different types:\n",
    "\n",
    "| Nominal | Ordinal | Numeric | Binary |\n",
    "| ------- | ------- | ------- | ------ |\n",
    "| Games   | City    | Age     |        |\n",
    "| Name    | Event   | Height  |        |\n",
    "| NOC     | ID      | Weight  |        |\n",
    "| Season  | Medal   | Year    |        |\n",
    "| Sex     |         |         |        |\n",
    "| Team    |         |         |        |\n",
    "\n",
    "To prepare the lab, we brought population data into the data set and changed all National Olympic Committee or `NOC` data points to match their corresponding `Country`. For countries without entries in the worldbank URL we hard-coded the populations. There were 106 observations in the data set not associated with a country, so we dropped them. These were `Refugee Athletes` and `Individual Olympic Athletes`. `Sex`, `Season`, and `Medal` were converted to numeric factors and `ID`, `NOC`, `Name`, `Team`, and `Games` were dropped due to lack of relevancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop = pd.read_csv('~/olympics/data/POP_TOTAL.csv', encoding = \"ISO-8859-1\")\n",
    "df_pop = df_pop[['Country Code', '2015']]\n",
    "#Change all Russia NOCs\n",
    "df['NOC'] = np.where(df['NOC'] == 'EUN', 'RUS', df['NOC'])\n",
    "df['NOC'] = np.where(df['NOC'] == 'URS', 'RUS', df['NOC'])\n",
    "#Change all Australia NOCs\n",
    "df['NOC'] = np.where(df['NOC'] == 'ANZ', 'AUS', df['NOC'])\n",
    "#Change all German NOCs\n",
    "df['NOC'] = np.where(df['NOC'] == 'FRG', 'GER', df['NOC'])\n",
    "df['NOC'] = np.where(df['NOC'] == 'GDR', 'GER', df['NOC'])\n",
    "df['NOC'] = np.where(df['NOC'] == 'SAA', 'GER', df['NOC'])\n",
    "#Change all Congo NOCs\n",
    "df['NOC'] = np.where(df['NOC'] == 'CGO', 'COD', df['NOC'])\n",
    "#Change all Czech NOCs\n",
    "df['NOC'] = np.where(df['NOC'] == 'BOH', 'CZE', df['NOC'])\n",
    "df['NOC'] = np.where(df['NOC'] == 'TCH', 'CZE', df['NOC'])\n",
    "#Change all Yemen NOCs\n",
    "df['NOC'] = np.where(df['NOC'] == 'YAR', 'YEM', df['NOC'])\n",
    "df['NOC'] = np.where(df['NOC'] == 'YMD', 'YEM', df['NOC'])\n",
    "#Change all Greek NOCs\n",
    "df['NOC'] = np.where(df['NOC'] == 'CRT', 'GRE', df['NOC'])\n",
    "#Change all Zimbabwe NOCs\n",
    "df['NOC'] = np.where(df['NOC'] == 'RHO', 'ZIM', df['NOC'])\n",
    "#Change all Malaysia NOCs\n",
    "df['NOC'] = np.where(df['NOC'] == 'MAL', 'MAS', df['NOC'])\n",
    "df['NOC'] = np.where(df['NOC'] == 'NBO', 'MAS', df['NOC'])\n",
    "#Change all Vietnam NOCs\n",
    "df['NOC'] = np.where(df['NOC'] == 'VNM', 'VIE', df['NOC'])\n",
    "#Change all Trinidad and Tobego NOCs\n",
    "df['NOC'] = np.where(df['NOC'] == 'WIF', 'TTO', df['NOC'])\n",
    "#Change all Trinidad and Tobego NOCs\n",
    "df['NOC'] = np.where(df['NOC'] == 'UAR', 'SYR', df['NOC'])\n",
    "#Change all Serbian NOCs\n",
    "df['NOC'] = np.where(df['NOC'] == 'SCG', 'YUG', df['NOC'])\n",
    "df['NOC'] = np.where(df['NOC'] == 'SRB', 'YUG', df['NOC'])\n",
    "#Change all Canada NOCs\n",
    "df['NOC'] = np.where(df['NOC'] == 'NFL', 'CAN', df['NOC'])\n",
    "df_pop.rename(index = str, columns = {'Country Code' : 'NOC', '2015': '2015 Population'}, inplace = True)\n",
    "df_pop_merge = pd.merge(left = df, right = df_pop, how = 'left', on=['NOC'], left_index=False)\n",
    "df_pop_merge.loc[df_pop_merge['Country'] == 'Taiwan', '2015 Population'] =  23485755\n",
    "df_pop_merge.loc[df_pop_merge['Country'] == 'Saint Vincent', '2015 Population'] =  109643\n",
    "df_pop_merge.loc[df_pop_merge['Country'] == 'Palestine', '2015 Population'] =  4817000\n",
    "df_pop_merge.loc[df_pop_merge['Country'] == 'Cook Islands', '2015 Population'] =  17459\n",
    "df_pop_merge.loc[df_pop_merge['Country'] == 'Eritrea', '2015 Population'] =  4846976\n",
    "df_pop_merge.loc[df_pop_merge['Country'] == 'Saint Kitts', '2015 Population'] =  54821\n",
    "df_pop_mergena = df_pop_merge[df_pop_merge['2015 Population'].isnull()]\n",
    "#Drop the 106 observations not associated with a country \n",
    "df_pop_merge = df_pop_merge.dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the population proportion for each country\n",
    "df_pop = df_pop_merge.groupby(['Country'])['2015 Population'].mean().reset_index()\n",
    "df_pop['Population_Prop'] = df_pop['2015 Population'].transform(lambda x: x / (x.sum()))\n",
    "\n",
    "#Calculate BMI for each athlete\n",
    "def calculate_bmi(df):\n",
    "    return (df[1]/(df[0] * df[0])) * 10000\n",
    "df_pop_merge['BMI'] = df_pop_merge[['Height', 'Weight']].apply(calculate_bmi, axis=1)\n",
    "\n",
    "#Merge dataframes with Population Propotion information\n",
    "df_pop_merge = pd.merge(left = df_pop_merge, right = df_pop, how = 'left', on=['Country'], \n",
    "                        left_index=False)\n",
    "#Create Binary Medal, Season, and Sex Classes\n",
    "df_pop_merge['Medal'] = np.where(df_pop_merge.Medal == 'No Medal', 0, 1)\n",
    "df_pop_merge['Season'] = np.where(df_pop_merge.Season == 'Summer', 1, 0)\n",
    "df_pop_merge['Sex'] = np.where(df_pop_merge.Sex == 'M', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Steve/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 38min 49s, sys: 12.6 s, total: 1h 39min 2s\n",
      "Wall time: 1h 39min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prev_medals = df_pop_merge.groupby(['Name', 'Year'])['Medal'].sum()\n",
    "prev_medals = prev_medals.reset_index()\n",
    "prev_medals.columns = ['Name', 'Year', 'Medal_Count']\n",
    "prev_medals['Previous_Medals'] = prev_medals['Medal_Count']\n",
    "\n",
    "for i in range(2, len(prev_medals)):\n",
    "    if prev_medals.iloc[i]['Name'] == prev_medals.iloc[i-1]['Name']:\n",
    "        if prev_medals.iloc[i-1]['Medal_Count'] != 0:\n",
    "            prev_medals['Previous_Medals'].iloc[i] = 1\n",
    "        else:\n",
    "            prev_medals['Previous_Medals'].iloc[i] = 0\n",
    "    else:\n",
    "        prev_medals['Previous_Medals'].iloc[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge prev_medals into existing pop_merge dataset to add Previous_Medals feature\n",
    "df_prev_medal_merge = pd.merge(left = df_pop_merge, right = prev_medals, how = 'left', on = ['Name', 'Year'])\n",
    "df_pop_merge = df_prev_medal_merge[['Country', 'Sex', 'Age', 'Height', 'Weight', 'Year', 'Season', 'Sport', 'Event', 'BMI', \n",
    "                             'Population_Prop', 'Medal', 'Previous_Medals']]\n",
    "\n",
    "#Write dataframe to .csv file in order to preserve the data and avoid Feature Engineering code in future iterations \n",
    "df_pop_merge.to_csv('~/olympics/data/pop_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 266848 entries, 0 to 266847\n",
      "Data columns (total 12 columns):\n",
      "Country            266848 non-null object\n",
      "Sex                266848 non-null int64\n",
      "Age                266848 non-null int64\n",
      "Height             266848 non-null int64\n",
      "Weight             266848 non-null int64\n",
      "Year               266848 non-null int64\n",
      "Season             266848 non-null int64\n",
      "Sport              266848 non-null object\n",
      "Event              266848 non-null object\n",
      "BMI                266848 non-null float64\n",
      "Population_Prop    266848 non-null float64\n",
      "Previous_Medals    266848 non-null int64\n",
      "dtypes: float64(2), int64(7), object(3)\n",
      "memory usage: 24.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Create X and y vectors for sklearn pre-processing steps\n",
    "df = pd.read_csv('~/olympics/data/pop_merge.csv')\n",
    "\n",
    "y = df['Medal']\n",
    "X = df.drop(['Medal', 'Unnamed: 0'], axis = 1)\n",
    "\n",
    "print(X.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Country`, `Sport`, and `Event` had too many variables for binary coding, so one-hot encoding was performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Sex            Age         Height         Weight  \\\n",
      "count  266848.000000  266848.000000  266848.000000  266848.000000   \n",
      "mean        0.722786      25.330338     175.420948      71.017542   \n",
      "std         0.447624       5.801661       9.869066      13.330644   \n",
      "min         0.000000      10.000000     127.000000      25.000000   \n",
      "25%         0.000000      21.000000     169.000000      62.000000   \n",
      "50%         1.000000      24.000000     176.000000      71.000000   \n",
      "75%         1.000000      28.000000     182.000000      78.000000   \n",
      "max         1.000000      72.000000     226.000000     214.000000   \n",
      "\n",
      "                Year         Season            BMI  Population_Prop  \\\n",
      "count  266848.000000  266848.000000  266848.000000    266848.000000   \n",
      "mean     1979.016369       0.818185      22.904691         0.013419   \n",
      "std        29.560519       0.385693       2.718862         0.028553   \n",
      "min      1896.000000       0.000000       8.360954         0.000001   \n",
      "25%      1960.000000       1.000000      21.258503         0.001362   \n",
      "50%      1988.000000       1.000000      22.783309         0.005258   \n",
      "75%      2004.000000       1.000000      24.163265         0.011266   \n",
      "max      2016.000000       1.000000      63.901580         0.181422   \n",
      "\n",
      "       Previous_Medals  Country_Afghanistan       ...         \\\n",
      "count    266848.000000        266848.000000       ...          \n",
      "mean          0.076883             0.000472       ...          \n",
      "std           0.266406             0.021725       ...          \n",
      "min           0.000000             0.000000       ...          \n",
      "25%           0.000000             0.000000       ...          \n",
      "50%           0.000000             0.000000       ...          \n",
      "75%           0.000000             0.000000       ...          \n",
      "max           1.000000             1.000000       ...          \n",
      "\n",
      "       Sport_Table Tennis  Sport_Taekwondo   Sport_Tennis  Sport_Trampolining  \\\n",
      "count       266848.000000    266848.000000  266848.000000        266848.00000   \n",
      "mean             0.007150         0.002271       0.010721             0.00057   \n",
      "std              0.084256         0.047600       0.102988             0.02386   \n",
      "min              0.000000         0.000000       0.000000             0.00000   \n",
      "25%              0.000000         0.000000       0.000000             0.00000   \n",
      "50%              0.000000         0.000000       0.000000             0.00000   \n",
      "75%              0.000000         0.000000       0.000000             0.00000   \n",
      "max              1.000000         1.000000       1.000000             1.00000   \n",
      "\n",
      "       Sport_Triathlon  Sport_Tug-Of-War  Sport_Volleyball  Sport_Water Polo  \\\n",
      "count    266848.000000     266848.000000     266848.000000     266848.000000   \n",
      "mean          0.001982          0.000637          0.012756          0.014375   \n",
      "std           0.044480          0.025232          0.112221          0.119032   \n",
      "min           0.000000          0.000000          0.000000          0.000000   \n",
      "25%           0.000000          0.000000          0.000000          0.000000   \n",
      "50%           0.000000          0.000000          0.000000          0.000000   \n",
      "75%           0.000000          0.000000          0.000000          0.000000   \n",
      "max           1.000000          1.000000          1.000000          1.000000   \n",
      "\n",
      "       Sport_Weightlifting  Sport_Wrestling  \n",
      "count        266848.000000    266848.000000  \n",
      "mean              0.014709         0.026776  \n",
      "std               0.120385         0.161427  \n",
      "min               0.000000         0.000000  \n",
      "25%               0.000000         0.000000  \n",
      "50%               0.000000         0.000000  \n",
      "75%               0.000000         0.000000  \n",
      "max               1.000000         1.000000  \n",
      "\n",
      "[8 rows x 791 columns]\n",
      "count    266848.000000\n",
      "mean          0.147841\n",
      "std           0.354943\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max           1.000000\n",
      "Name: Medal, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X = pd.get_dummies(X, columns = ['Country', 'Event', 'Sport'])\n",
    "print(X.describe())\n",
    "print(y.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#Standardize X\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X_std = sc.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2\n",
    "\n",
    "- (5pts) Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three variables were added to the data set: `Population_Prop`, `BMI`, and `Previous Medals`. The `Population_Prop` variable was added to represent the percentage of the overall world population for a given `Country`. Athlete `BMI` was added to the dataframe where $\\omega$ represents `Weight` in kilograms, and $\\eta$ represents `Height` in centimeters, and $C$ is a constant at `10,000`:\n",
    "\n",
    "$$\n",
    "BMI = \\left(\\frac{\\omega}{\\eta \\eta}\\right) C\n",
    "$$\n",
    "\n",
    "`Previous_Medals` was created as a binary representation if an athlete had won a medal at a previous Olympic games (indicated by a `1`). The `Medal` variable was converted from ordinal to binary, where `Gold`, `Silver`, or `Bronze` were given a `1` and `No Medal` performers were given a `0`. `Season` and `Sex` were also converted to binary. \n",
    "\n",
    "One-hot encoding was performed for binarization of the remaining nominal variables(`Country`, `Event`, and `Sport`) so they could be included as features to train the classification model.\n",
    "\n",
    "The final data set contains the following data of different types:\n",
    "\n",
    "| Nominal | Ordinal | Numeric         | Binary          |\n",
    "| ------- | ------- | --------------- | --------------- | \n",
    "|         |         | Age             | Country         |\n",
    "|         |         | BMI             | Event           |\n",
    "|         |         | Height          | Medal           |\n",
    "|         |         | Population_Prop | Previous-Medals |\n",
    "|         |         | Weight          | Season          |\n",
    "|         |         | Year            | Sex             |\n",
    "|         |         |                 | Sport           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling and Evaluation\n",
    "\n",
    "#### Section 1\n",
    "\n",
    "- (10 pts) Choose and explain your evaluation metrics that you will use (i.e., accuracy, precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2\n",
    "\n",
    "- (10pts) Choose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 3\n",
    "\n",
    "- (20pts) Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifer Estimator created and edited from Professor Drew's NC school repository\n",
    "def EvaluateClassifierEstimator2(classifierEstimator, X, y, cv):\n",
    "    \n",
    "    #Perform cross validation \n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    predictions = cross_val_predict(classifierEstimator, X, y, cv=cv)\n",
    "    \n",
    "    #model evaluation \n",
    "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score \n",
    "    \n",
    "    #pass true test set values and predictions to classification_report\n",
    "    classReport = classification_report(y, predictions)\n",
    "    confMat = confusion_matrix(y, predictions)\n",
    "    acc = accuracy_score(y, predictions)\n",
    "\n",
    "    \n",
    "    print(classReport)\n",
    "    print(confMat)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logisitic regression 10-fold cross-validation \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "lr = LogisticRegression()\n",
    "\n",
    "\n",
    "parameters = { 'penalty':['l2','l1']\n",
    "              ,'C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "              ,'class_weight': ['balanced','none']\n",
    "              ,'random_state': [0]\n",
    "              ,'solver': ['sag', 'saga']\n",
    "              ,'max_iter':[100,500]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "regGS = GridSearchCV(estimator=lr\n",
    "                   , n_jobs=-1 #Use all possible cores to run jobs in parallel\n",
    "                   , verbose=True\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring='f1')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGS.fit(X_std, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateClassifierEstimator2(lr_clf, X_std, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = lr_clf.fit(X_std, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "gs_lr_model = 'gs_lr_model.joblib.pkl'\n",
    "_ = joblib.dump(lr_clf, gs_lr_model, compress = 9)\n",
    "#This will save the model in your working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = joblib.load(gs_lr_model)\n",
    "clf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4\n",
    "\n",
    "- (10pts) Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 5\n",
    "\n",
    "- (10pts) Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniquesâ€”be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 6\n",
    "\n",
    "- (10pts) Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "- (5pts) How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.? \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These predictions could be used for predicting medal winners in future Olympics based on variables such as `BMI`, `Height`, `Weight`, or `Sex`; however, this is a bit impractical due to the lack of discernable difference in skillset. Individuals with similar characteristics do not necessarily perform the same. To make podium predictions more useful we would need a skill level metric, but skill levels change over time. Consequently, this data set is better served for informational or educational purposes.\n",
    "\n",
    "To teach an individual or organization about <i>data science</i>, <i>machine learning</i>, or <i>data mining</i> we must first produce something relatable and <u>this</u> data set is something people understand, so as we explain what classifications we are making the content becomes understandable. From there we can dive into data that is more relavent to that individual or organization.\n",
    "\n",
    "Binary and multinomial classification have numerous use cases across industries. For example:\n",
    "\n",
    "| Industry      | Use Case                |\n",
    "| ------------- | ----------------------- |\n",
    "| Advertising   | Targeted advertising    |\n",
    "| Energy        | Prediction of dry well  |\n",
    "| Manufacturing | Risk of machine failure |\n",
    "| Sports        | Run or pass in football |\n",
    "| Telecom       | Customer retention      |\n",
    "| Underwriting  | Risk level of borrower  |\n",
    "\n",
    "To <b>measure the value</b> of any prediciton model we would develop a business case. To do this we would quantify risk reduction, revenue increases, changes in working capital, and/or cost decreases that were a direct result of the model. Next we would determine the cost of implementing the model and perform a discounted cash flow analysis to ensure there was a positive return on investment.\n",
    "\n",
    "To <b>deploy</b> a model under any of the aforementioned use cases we would need to understand the architecture environment and determine how to use APIs to connect to the classification model. Once this is established the predictor could be integrated with an existing system or set up on a clean build.\n",
    "\n",
    "It may take many hours to <b>train</b> a prediction model, so it would be impractical to retrain a model in real-time using a relational database. Instead, the frequency for updating the prediction model would need to be determined by the nature of the use case. Using the telecom example from above, customer retention prediction models would likely run monthly to align with billing and usage limits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exceptional Work\n",
    "\n",
    "- (10pts) You have free reign to provide additional analyses. One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes. Which parameters are most significant for making a good model for each classification algorithm?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
